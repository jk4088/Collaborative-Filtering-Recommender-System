setwd("~/Documents/GitHub/Spring2018/Project_Starter_Codes/Project2-PredictiveModelling/doc")
knitr::opts_chunk$set(echo = TRUE)
library("EBImage")
library("gbm")
img_train_dir  <- "../../../../Proj2_Data/train/" # This is where my data lives (outside of Spring2018)
n_files <- length(list.files(img_train_dir))
n_files
list.files(img_train_dir)
length(list.files(img_train_dir))
n_files <- length(list.files(img_train_dir))
n_files
dat <- matrix(NA, nrow = n_files, ncol = 3)
for(i in 1:n_files){
img <- readImage(paste0(img_train_dir,  "pet", i, ".jpg"))
dat[i, 1:length(dim(img))] <- dim(img)
}
# How many B/W images?  All color.
table(dat[, 3])
# How many rows? A lot at 500 rows.  Maybe a good subset to consider.
table(dat[, 1])
cv.function <- function(X.train, y.train, d, K) {
n        <- length(y.train)
n.fold   <- floor(n/K)
s        <- sample(rep(1:K, c(rep(n.fold, K-1), n-(K-1)*n.fold)))
cv.error <- rep(NA, K)
for (i in 1:K){
train.data  <- X.train[s != i,]
train.label <- y.train[s != i]
test.data   <- X.train[s == i,]
test.label  <- y.train[s == i]
par  <- list(depth = d)
fit  <- train(train.data, train.label, par)
pred <- test(fit, test.data)
cv.error[i] <- mean(pred != test.label)
}
return(c(mean(cv.error), sd(cv.error)))
}
model_values <- seq(3, 11, 2)
model_labels <- paste("GBM with depth =", model_values)
la
lab
n_r    <- 500
subset <- which(dat[,1] == n_r)
### store vectorized pixel values of images
dat <- matrix(NA, length(subset), n_r)
for(i in subset){
img     <- readImage(paste0(img_train_dir,  "pet", i, ".jpg"))
dat[i,] <- rowMeans(img)
}
i
rowMeans(img)
n_r    <- 500
subset <- which(dat[,1] == n_r)
### store vectorized pixel values of images
dat <- matrix(NA, length(subset), n_r)
row <- 1
for(i in subset){
img     <- readImage(paste0(img_train_dir,  "pet", i, ".jpg"))
dat[row,] <- rowMeans(img)
row <- row + 1
}
label_train <- read.csv("../../../../Proj2_Data/train_label.txt", header = F)
label_train <- read.csv("../../../../Proj2_Data/train_label.txt", header = F)
label_train <- as.numeric(unlist(label_train) == "cat")
label_train
label_train <- label_train[subset]
dim(da)
dim(dat)
n_r    <- 500
subset <- which(dat[,1] == n_r)
### store vectorized pixel values of images
dat <- matrix(NA, length(subset), n_r)
row <- 1
dat
dim(dat)
n_files <- length(list.files(img_train_dir))
### store image dimensions
dat <- matrix(NA, nrow = n_files, ncol = 3)
for(i in 1:n_files){
img <- readImage(paste0(img_train_dir,  "pet", i, ".jpg"))
dat[i, 1:length(dim(img))] <- dim(img)
}
# How many B/W images?  All color.
table(dat[, 3])
# How many rows? A lot at 500 rows.  Maybe a good subset to consider.
table(dat[, 1])
n_r    <- 500
subset <- which(dat[,1] == n_r)
### store vectorized pixel values of images
dat <- matrix(NA, length(subset), n_r)
row <- 1
dim(dat)
for(i in subset){
img     <- readImage(paste0(img_train_dir,  "pet", i, ".jpg"))
dat[row,] <- rowMeans(img)
row <- row + 1
}
model_values <- seq(3, 11, 2)
model_labels <- paste("GBM with depth =", model_values)
label_train <- read.csv("../../../../Proj2_Data/train_label.txt", header = F)
label_train <- as.numeric(unlist(label_train) == "cat")
label_train <- label_train[subset]
length(label_train)
err_cv <- array(dim = c(length(model_values), 2))
for(k in 1:length(model_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.function(dat, label_train, model_values[k], K)
}
K <- 5
err_cv <- array(dim = c(length(model_values), 2))
for(k in 1:length(model_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.function(dat, label_train, model_values[k], K)
}
K <- 5
err_cv <- array(dim = c(length(model_values), 2))
for(k in 1:length(model_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.function(dat, label_train, model_values[k], K)
}
train <- function(dat_train, label_train, par = NULL){
### Train a Gradient Boosting Model (GBM) using processed features from training images
### Input:
###  -  processed features from images
###  -  class labels for training images
### Output: training model specification
### load libraries
library("gbm")
### Train with gradient boosting model
if(is.null(par)){
depth <- 3
} else {
depth <- par$depth
}
fit_gbm <- gbm.fit(x = dat_train, y = label_train,
n.trees = 2000,
distribution = "bernoulli",
interaction.depth = depth,
bag.fraction = 0.5,
verbose = FALSE)
best_iter <- gbm.perf(fit_gbm, method = "OOB", plot.it = FALSE)
return(list(fit = fit_gbm, iter = best_iter))
}
K <- 5
err_cv <- array(dim = c(length(model_values), 2))
for(k in 1:length(model_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.function(dat, label_train, model_values[k], K)
}
source("../lib/cross_validation.R")
source("../lib/train.R")
source("../lib/test.R")
model_values <- seq(3, 11, 2)
model_labels <- paste("GBM with depth =", model_values)
label_train <- read.csv("../../../../Proj2_Data/train_label.txt", header = F)
label_train <- as.numeric(unlist(label_train) == "cat")
label_train <- label_train[subset]
K <- 5
err_cv <- array(dim = c(length(model_values), 2))
for(k in 1:length(model_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.function(dat, label_train, model_values[k], K)
}
warnings()
plot(model_values, err_cv[,1], xlab = "Interaction Depth", ylab = "CV Error",
main = "Cross Validation Error", type = "n", ylim = c(0, 0.25))
points(model_values, err_cv[,1], col = "blue", pch=16)
lines(model_values, err_cv[,1], col = "blue")
arrows(model_values, err_cv[,1] - err_cv[,2], model_values, err_cv[,1] + err_cv[,2],
length = 0.1, angle = 90, code = 3)
err_cv[,1]
err_cv
model_best <- model_values[1]
if(run.cv){
model_best <- model_values[which.min(err_cv[, 1])]
}
par_best <- list(depth = model_best)
model_best <- model_values[which.min(err_cv[, 1])]
par_best <- list(depth = model_best)
par_best
tm_train <- NA
tm_train <- system.time(fit_train <- train(dat_train, label_train, par_best))
tm_train <- NA
tm_train <- system.time(fit_train <- train(dat, label_train, par_best))
getwd()
source("functions.R")
source("../lib/functions.R")
setwd("/Users/wcheng/Downloads/Proj3_Data/MS_sample")
MS_train <- read.csv("data_train.csv", as.is = TRUE, header = TRUE)
MS_train <- MS_train[, 2:4]
MS_UI <- MS_data_transform(MS_train)
save(MS_UI, file = "MS_UI.RData")
visit_nums <- rowSums(MS_UI != 0)
table(visit_nums)
mean(visit_nums)
median(visit_nums)
# Looping instead of rowSums()
long.row.sums <- function(UI) {
vec <- rep(NA, nrow(UI))
for (i in 1:nrow(UI)) {
vec[i] <- sum(UI[i,], na.rm = TRUE)
}
return(vec)
}
system.time(long.row.sums(MS_UI))
system.time(rowSums(MS_UI, na.rm = TRUE))
vec <- long.row.sums(MS_UI)
all(vec == rowSums(MS_UI, na.rm = TRUE))
setwd("/Users/wcheng/Downloads/Proj3_Data/eachmovie_sample")
movie_train <- read.csv("data_train.csv", as.is = TRUE, header = TRUE)
movie_train <- movie_train[, 2:4]
users  <- sort(unique(movie_train$User))
movies <- sort(unique(movie_train$Movie))
UI            <- matrix(NA, nrow = length(users), ncol = length(movies))
row.names(UI) <- users
colnames(UI)  <- movies
movies  <- movie_train$Movie[movie_train$User == users[1]]
ratings <- movie_train$Score[movie_train$User == users[1]]
ord     <- order(movies)
movies  <- movies[ord]
ratings <- ratings[ord]
system.time(UI[1, colnames(UI) %in% movies] <- ratings)
long.in <- function(movies, ratings) {
# Cycle through the ratings, find the corresponding column
for (i in 1:length(ratings)) {
column <- which(colnames(UI) == movies[i])
UI[2, column] <- ratings[i]
print(column)
}
}
system.time(long.in(movies, ratings))
all(UI[1, ] == UI[2,], na.rm = TRUE)
movie_UI <- movie_data_transform(movie_train)
save(movie_UI, file = "movie_UI.RData")
total_ratings <- rowSums(movie_UI, na.rm = TRUE)
table(total_ratings)
mean(total_ratings)
median(total_ratings)
View(MS_UI)
movie_UI         <- as.matrix(movie_UI)
movie_sim_weight <- matrix(NA, nrow = nrow(movie_UI), ncol = nrow(movie_UI))
rowA <- movie_UI[1, ]
rowB <- movie_UI[2, ]
cor(rowA, rowB, method = 'pearson', use = "pairwise.complete.obs")
joint_values <- !is.na(rowA) & !is.na(rowB)
cor(rowA[joint_values], rowB[joint_values], method = 'pearson')
system.time(vec1 <- apply(movie_UI, 1, cor, movie_UI[1, ], method = 'pearson', use = "pairwise.complete.obs"))
View(UI)
View(UI)
all(UI[1, ] == UI[2,], na.rm = TRUE)
View(movie_UI)
long.way <- function(row.num) {
for(i in 1:nrow(movie_UI)) {
movie_sim_weight[row.num, i] <- cor(movie_UI[i, ], movie_UI[row.num, ], method = 'pearson', use = "pairwise.complete.obs")
}
}
system.time(long.way(1))
movie_sim <- calc_weight(movie_UI)
